{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb658ea",
   "metadata": {},
   "source": [
    "# ðŸ“„ Crime Data Preprocessing Documentation\n",
    "\n",
    "This notebook documents the full preprocessing pipeline for combining, cleaning, and engineering features from UK crime data.\n",
    "\n",
    "### Key objectives:\n",
    "- Combine monthly crime data across all regions\n",
    "- Merge with deprivation and civic infrastructure metadata\n",
    "- Handle missing values, duplicates, and data types\n",
    "- Engineer new variables for analysis\n",
    "- Prepare for time series modelling and EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb1a5a",
   "metadata": {},
   "source": [
    "## ðŸ” High-Level Preprocessing Flowchart (Mermaid)\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph LOAD_AND_MERGE[Data Loading and Merging]\n",
    "        A[Loop through month folders]\n",
    "        B[Loop through CSV files in each folder]\n",
    "        C[Extract Force and Month]\n",
    "        D[Append to list]\n",
    "        E[Concatenate to one DataFrame]\n",
    "        F[Load deprivation and civic CSVs]\n",
    "        G[Rename LSOA columns]\n",
    "        H[Merge deprivation + civic data]\n",
    "        I[Merge with crime data]\n",
    "        A --> B --> C --> D --> E\n",
    "        E --> F --> G --> H --> I\n",
    "    end\n",
    "\n",
    "    subgraph CLEANING[Initial Cleaning]\n",
    "        J[Drop irrelevant columns]\n",
    "        K[Loop: Convert object columns to numeric]\n",
    "        L[Convert Month + categoricals]\n",
    "        M[Rename columns]\n",
    "        N[Drop missing LSOA]\n",
    "        I --> J --> K --> L --> M --> N\n",
    "    end\n",
    "\n",
    "    subgraph IDS_AND_OUTCOMES[IDs and Outcome Handling]\n",
    "        O[Loop: Generate UUIDs]\n",
    "        P[Drop row duplicates]\n",
    "        Q[New unique ID per row]\n",
    "        R[Fill 'Last outcome' nulls]\n",
    "        N --> O --> P --> Q --> R\n",
    "    end\n",
    "\n",
    "    subgraph IMPUTATION[Handling Missing Values]\n",
    "        S[Loop: Impute by LSOA]\n",
    "        T[Check LSOA completeness]\n",
    "        U[Loop: Fallback by Force]\n",
    "        V[Drop null-heavy cols]\n",
    "        R --> S --> T --> U --> V\n",
    "    end\n",
    "\n",
    "    subgraph FEATURE_ENGINEERING[Feature Engineering]\n",
    "        W[Create service access score]\n",
    "        X[Create crime count per LSOA]\n",
    "        Y[Sort by Force + Month]\n",
    "        Z[Create lagged crime count]\n",
    "        AA[Map crime types to categories]\n",
    "        AB[Reverse rank/decile scales]\n",
    "        V --> W --> X --> Y --> Z --> AA --> AB\n",
    "    end\n",
    "\n",
    "    AB --> AC[Save final CSV]\n",
    "\n",
    "    classDef loop stroke:#000,stroke-width:2px,stroke-dasharray: 5 5;\n",
    "    B:::loop\n",
    "    K:::loop\n",
    "    O:::loop\n",
    "    S:::loop\n",
    "    U:::loop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9962363e-fdd7-4e70-8672-e39f5e9227ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Local\\Temp\\ipykernel_14624\\2100105958.py\", line 2, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\__init__.py\", line 2, in <module>\n",
      "    from .rcmod import *  # noqa: F401,F403\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\rcmod.py\", line 5, in <module>\n",
      "    from . import palettes\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\palettes.py\", line 9, in <module>\n",
      "    from .utils import desaturate, get_color_cycle\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py\", line 11, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Local\\Temp\\ipykernel_14624\\2100105958.py\", line 2, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\__init__.py\", line 2, in <module>\n",
      "    from .rcmod import *  # noqa: F401,F403\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\rcmod.py\", line 5, in <module>\n",
      "    from . import palettes\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\palettes.py\", line 9, in <module>\n",
      "    from .utils import desaturate, get_color_cycle\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py\", line 11, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Local\\Temp\\ipykernel_14624\\2100105958.py\", line 2, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\__init__.py\", line 2, in <module>\n",
      "    from .rcmod import *  # noqa: F401,F403\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\rcmod.py\", line 5, in <module>\n",
      "    from . import palettes\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\palettes.py\", line 9, in <module>\n",
      "    from .utils import desaturate, get_color_cycle\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py\", line 11, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hanam\\AppData\\Local\\Temp\\ipykernel_14624\\2100105958.py\", line 2, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\__init__.py\", line 2, in <module>\n",
      "    from .rcmod import *  # noqa: F401,F403\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\rcmod.py\", line 5, in <module>\n",
      "    from . import palettes\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\palettes.py\", line 9, in <module>\n",
      "    from .utils import desaturate, get_color_cycle\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py\", line 11, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\hanam\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace34a20-7692-45ae-8442-4e5a893cab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Combined shape: (3763863, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>Crime type</th>\n",
       "      <th>Last outcome category</th>\n",
       "      <th>Context</th>\n",
       "      <th>Force</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50adc6e18bdf475cdae2ef77fec2e4dc29c97ec97cb0d0...</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.115997</td>\n",
       "      <td>51.527254</td>\n",
       "      <td>On or near Cubitt Street</td>\n",
       "      <td>E01000936</td>\n",
       "      <td>Camden 024A</td>\n",
       "      <td>Other crime</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>city-of-london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26c9f8b125c7a15d6515bd4f95d679693d5a883b619f02...</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.110350</td>\n",
       "      <td>51.518090</td>\n",
       "      <td>On or near Holborn</td>\n",
       "      <td>E01000917</td>\n",
       "      <td>Camden 027C</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>city-of-london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f6a5bf218eaad8e135fdb9d87c4dba04f4084944aab18...</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>city-of-london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54d2a39fab2279b6d0e852844c16ec46c1f6948a386adc...</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>city-of-london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00959f6007b7e60d2a377c39ae837a20803a9a6d52d3fc...</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>51.515942</td>\n",
       "      <td>On or near</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>city-of-london</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Crime ID    Month  \\\n",
       "0  50adc6e18bdf475cdae2ef77fec2e4dc29c97ec97cb0d0...  2023-02   \n",
       "1  26c9f8b125c7a15d6515bd4f95d679693d5a883b619f02...  2023-02   \n",
       "2  5f6a5bf218eaad8e135fdb9d87c4dba04f4084944aab18...  2023-02   \n",
       "3  54d2a39fab2279b6d0e852844c16ec46c1f6948a386adc...  2023-02   \n",
       "4  00959f6007b7e60d2a377c39ae837a20803a9a6d52d3fc...  2023-02   \n",
       "\n",
       "             Reported by           Falls within  Longitude   Latitude  \\\n",
       "0  City of London Police  City of London Police  -0.115997  51.527254   \n",
       "1  City of London Police  City of London Police  -0.110350  51.518090   \n",
       "2  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "3  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "4  City of London Police  City of London Police  -0.112096  51.515942   \n",
       "\n",
       "                   Location  LSOA code    LSOA name   Crime type  \\\n",
       "0  On or near Cubitt Street  E01000936  Camden 024A  Other crime   \n",
       "1        On or near Holborn  E01000917  Camden 027C  Other theft   \n",
       "2  On or near Chancery Lane  E01000914  Camden 028B  Other theft   \n",
       "3  On or near Chancery Lane  E01000914  Camden 028B  Other theft   \n",
       "4               On or near   E01000914  Camden 028B  Other theft   \n",
       "\n",
       "                           Last outcome category  Context           Force  \n",
       "0                      Status update unavailable      NaN  city-of-london  \n",
       "1  Investigation complete; no suspect identified      NaN  city-of-london  \n",
       "2  Investigation complete; no suspect identified      NaN  city-of-london  \n",
       "3                      Status update unavailable      NaN  city-of-london  \n",
       "4  Investigation complete; no suspect identified      NaN  city-of-london  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Use current working directory\n",
    "base_path = Path(\".\")\n",
    "\n",
    "street_dfs = []\n",
    "\n",
    "for month_folder in sorted(base_path.iterdir()):\n",
    "    if not month_folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    month = month_folder.name \n",
    "\n",
    "    for file in month_folder.glob(\"*.csv\"):\n",
    "        filename = file.stem.lower()\n",
    "        parts = filename.split(\"-\")\n",
    "\n",
    "        force = \"-\".join(parts[2:-1])  \n",
    "        df = pd.read_csv(file)\n",
    "        df['Month'] = month\n",
    "        df['Force'] = force\n",
    "\n",
    "        street_dfs.append(df)\n",
    "\n",
    "# Combine everything\n",
    "all_street_df = pd.concat(street_dfs, ignore_index=True)\n",
    "\n",
    "# Check\n",
    "print(\"âœ… Combined shape:\", all_street_df.shape)\n",
    "all_street_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed06318-ccfc-45c2-82bd-064a6ddb0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "deprivation_df = pd.read_csv(\"deprivation LSOA.csv\")\n",
    "civic_df = pd.read_csv(\"Civic infrastructure LSOA.csv\") #loading additional data to merge with the stacked data\n",
    "#this data includes service access data, income, education, living environment, and homelessness data and it's relation to crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7547d9d2-b3db-4408-b8c3-2216131b1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for consistent join key\n",
    "deprivation_df.rename(columns={'LSOA code (2011)': 'LSOA code'}, inplace=True)\n",
    "civic_df.rename(columns={'LSOA code (2011)': 'LSOA code'}, inplace=True)\n",
    "\n",
    "# Merge deprivation and infrastructure into one LSOA metadata table\n",
    "combined_lsoa_data = pd.merge(deprivation_df, civic_df, on='LSOA code', how='outer')\n",
    "\n",
    "# Now merge that with the crime data using LSOA code\n",
    "final_df = all_street_df.merge(combined_lsoa_data, on='LSOA code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4243acc7-819f-4573-8bbf-af8434f6427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"merged_raw_data.csv\", index=False)\n",
    "#File is too large for me to upload on sharepoint so user needs to download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8099d8dd-429d-4757-ba41-b20d54297b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_raw_data.csv\") #loading final stacked/merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3677b45c-89fa-4a8c-9e2b-2ac1aa21c209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude',\n",
       "       'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type',\n",
       "       'Last outcome category', 'Context', 'Force', 'LSOA name_x',\n",
       "       'Local Authority District code (2019)_x',\n",
       "       'Local Authority District name (2019)_x',\n",
       "       'Index of Multiple Deprivation (IMD) Rank (where 1 is most deprived)',\n",
       "       'Index of Multiple Deprivation (IMD) Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Income Rank (where 1 is most deprived)',\n",
       "       'Income Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Employment Rank (where 1 is most deprived)',\n",
       "       'Employment Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Education, Skills and Training Rank (where 1 is most deprived)',\n",
       "       'Education, Skills and Training Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Health Deprivation and Disability Rank (where 1 is most deprived)',\n",
       "       'Health Deprivation and Disability Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Crime Rank (where 1 is most deprived)',\n",
       "       'Crime Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Barriers to Housing and Services Rank (where 1 is most deprived)',\n",
       "       'Barriers to Housing and Services Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'Living Environment Rank (where 1 is most deprived)',\n",
       "       'Living Environment Decile (where 1 is most deprived 10% of LSOAs)',\n",
       "       'LSOA name_y', 'Local Authority District code (2019)_y',\n",
       "       'Local Authority District name (2019)_y',\n",
       "       'Road distance to a post office indicator (km)',\n",
       "       'Road distance to a primary school indicator (km)',\n",
       "       'Road distance to general store or supermarket indicator (km)',\n",
       "       'Road distance to a GP surgery indicator (km)',\n",
       "       'Household overcrowding indicator',\n",
       "       'Homelessness indicator (rate per 1000 households)',\n",
       "       'Owner-occupation affordability (component of housing affordability indicator)',\n",
       "       'Private rental affordability (component of housing affordability indicator)',\n",
       "       'Housing affordability indicator'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #inspecting data to do further cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8bb7c-72b5-48fd-8b12-d5a244fcf557",
   "metadata": {},
   "source": [
    "## **Dropping columns**\n",
    "\n",
    "I dropped information on longitude and latitude as it include coordinates not useful for EDA. \n",
    "\n",
    "Context column was full of N/A data, removed repeated location based columns, housing affordability and similar columns etc. don't have strong ties to crime-- income/education/living environment etc. acts as more of a key predictor then housing affordability which I opted for instead. \n",
    "\n",
    "Local authority districts were not joined on and had no ties to the original crime/police data henced I removed it, and index of multiple deprivation lacked granularity compared to other indexes/ rank data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b04cf61b-9d47-405b-901d-90e1c8205206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "columns_to_drop = [\n",
    "    'Longitude', 'Latitude', 'Reported by', 'Context', 'Falls within',\n",
    "    'Local Authority District code (2019)_x', 'Local Authority District name (2019)_x',\n",
    "    'Owner-occupation affordability (component of housing affordability indicator)',\n",
    "    'Private rental affordability (component of housing affordability indicator)',\n",
    "    'Housing affordability indicator',\n",
    "    'Local Authority District code (2019)_y', 'Local Authority District name (2019)_y',\n",
    "    'Household overcrowding indicator', 'Index of Multiple Deprivation (IMD) Rank (where 1 is most deprived)','Index of Multiple Deprivation (IMD) Decile (where 1 is most deprived 10% of LSOAs)','Health Deprivation and Disability Rank (where 1 is most deprived)','Health Deprivation and Disability Decile (where 1 is most deprived 10% of LSOAs)'\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f133b6c-9958-4052-a0d3-77a38d31990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crime ID                                                                            object\n",
       "Month                                                                               object\n",
       "Location                                                                            object\n",
       "LSOA code                                                                           object\n",
       "LSOA name                                                                           object\n",
       "Crime type                                                                          object\n",
       "Last outcome category                                                               object\n",
       "Force                                                                               object\n",
       "LSOA name_x                                                                         object\n",
       "Income Rank (where 1 is most deprived)                                              object\n",
       "Income Decile (where 1 is most deprived 10% of LSOAs)                              float64\n",
       "Employment Rank (where 1 is most deprived)                                          object\n",
       "Employment Decile (where 1 is most deprived 10% of LSOAs)                          float64\n",
       "Education, Skills and Training Rank (where 1 is most deprived)                      object\n",
       "Education, Skills and Training Decile (where 1 is most deprived 10% of LSOAs)      float64\n",
       "Crime Rank (where 1 is most deprived)                                               object\n",
       "Crime Decile (where 1 is most deprived 10% of LSOAs)                               float64\n",
       "Barriers to Housing and Services Rank (where 1 is most deprived)                    object\n",
       "Barriers to Housing and Services Decile (where 1 is most deprived 10% of LSOAs)    float64\n",
       "Living Environment Rank (where 1 is most deprived)                                  object\n",
       "Living Environment Decile (where 1 is most deprived 10% of LSOAs)                  float64\n",
       "LSOA name_y                                                                         object\n",
       "Road distance to a post office indicator (km)                                      float64\n",
       "Road distance to a primary school indicator (km)                                   float64\n",
       "Road distance to general store or supermarket indicator (km)                       float64\n",
       "Road distance to a GP surgery indicator (km)                                       float64\n",
       "Homelessness indicator (rate per 1000 households)                                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #ensuring data is in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d98d48-59eb-44f9-90a5-6917b02d1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numerical columns from object to numeric\n",
    "columns_to_convert = [\n",
    "    'Income Rank (where 1 is most deprived)',\n",
    "    'Employment Rank (where 1 is most deprived)',\n",
    "    'Education, Skills and Training Rank (where 1 is most deprived)',\n",
    "    'Barriers to Housing and Services Rank (where 1 is most deprived)',\n",
    "    'Living Environment Rank (where 1 is most deprived)','Crime Rank (where 1 is most deprived)'\n",
    "]\n",
    "\n",
    "#converting each object in the list to numeric type using a for loop \n",
    "for col in columns_to_convert:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "#converting categories into categorical data \n",
    "df['Crime type'] = df['Crime type'].astype('category')\n",
    "df['Force'] = df['Force'].astype('category')\n",
    "\n",
    "#converting month/year column into date \n",
    "df['Month'] = pd.to_datetime(df['Month'], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958c3693-c4a7-44cb-b18d-49acd60515eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming decile and rank columns as shorter/ easier column names\n",
    "\n",
    "rename_dict = {\n",
    "    'Income Rank (where 1 is most deprived)': 'Income Deprivation Rank',\n",
    "    'Income Decile (where 1 is most deprived 10% of LSOAs)': 'Income Deprivation Decile',\n",
    "    'Employment Rank (where 1 is most deprived)': 'Employment Deprivation Rank',\n",
    "    'Employment Decile (where 1 is most deprived 10% of LSOAs)': 'Employment Deprivation Decile',\n",
    "    'Education, Skills and Training Rank (where 1 is most deprived)': 'Education Deprivation Rank',\n",
    "    'Education, Skills and Training Decile (where 1 is most deprived 10% of LSOAs)': 'Education Deprivation Decile',\n",
    "    'Barriers to Housing and Services Rank (where 1 is most deprived)': 'Housing Barrier Rank',\n",
    "    'Barriers to Housing and Services Decile (where 1 is most deprived 10% of LSOAs)': 'Housing Barrier Decile',\n",
    "    'Living Environment Rank (where 1 is most deprived)': 'Environment Deprivation Rank',\n",
    "    'Living Environment Decile (where 1 is most deprived 10% of LSOAs)': 'Environment Deprivation Decile',\n",
    "    'Road distance to a post office indicator (km)': 'Distance to Post Office (km)',\n",
    "    'Road distance to a primary school indicator (km)': 'Distance to Primary School (km)',\n",
    "    'Road distance to general store or supermarket indicator (km)': 'Distance to Supermarket (km)',\n",
    "    'Road distance to a GP surgery indicator (km)': 'Distance to GP (km)',\n",
    "    'Homelessness indicator (rate per 1000 households)': 'Homelessness Rate', \n",
    "    'Crime Rank (where 1 is most deprived)': 'Crime Deprivation Rank',\n",
    "    'Crime Decile (where 1 is most deprived 10% of LSOAs)': 'Crime Deprivation Decile'\n",
    "}\n",
    "\n",
    "df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6731b8e0-d24f-4572-b781-ac7db6b9f5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Crime ID', 'Month', 'Location', 'LSOA code', 'LSOA name', 'Crime type',\n",
       "       'Last outcome category', 'Force', 'LSOA name_x',\n",
       "       'Income Deprivation Rank', 'Income Deprivation Decile',\n",
       "       'Employment Deprivation Rank', 'Employment Deprivation Decile',\n",
       "       'Education Deprivation Rank', 'Education Deprivation Decile',\n",
       "       'Crime Deprivation Rank', 'Crime Deprivation Decile',\n",
       "       'Housing Barrier Rank', 'Housing Barrier Decile',\n",
       "       'Environment Deprivation Rank', 'Environment Deprivation Decile',\n",
       "       'LSOA name_y', 'Distance to Post Office (km)',\n",
       "       'Distance to Primary School (km)', 'Distance to Supermarket (km)',\n",
       "       'Distance to GP (km)', 'Homelessness Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #inspecting final columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d261143-8ba9-4505-bd58-4363c6143931",
   "metadata": {},
   "source": [
    "### **Missing data identification**\n",
    "\n",
    "Now that I've dropped redundant data and casted data into proper/ more accurate data types I can now remove missing data. First I will identify data before removing and imputing. I will also remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c1ccdf-dcbf-4253-9efe-f5a371a4ba07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crime ID                            584573\n",
       "Month                                    0\n",
       "Location                                 0\n",
       "LSOA code                            32486\n",
       "LSOA name                            32486\n",
       "Crime type                               0\n",
       "Last outcome category               584573\n",
       "Force                                    0\n",
       "LSOA name_x                         330222\n",
       "Income Deprivation Rank            3632656\n",
       "Income Deprivation Decile           330222\n",
       "Employment Deprivation Rank        3675329\n",
       "Employment Deprivation Decile       330222\n",
       "Education Deprivation Rank         3649030\n",
       "Education Deprivation Decile        330222\n",
       "Crime Deprivation Rank             3512139\n",
       "Crime Deprivation Decile            330222\n",
       "Housing Barrier Rank               3479927\n",
       "Housing Barrier Decile              330222\n",
       "Environment Deprivation Rank       3491631\n",
       "Environment Deprivation Decile      330222\n",
       "LSOA name_y                         330222\n",
       "Distance to Post Office (km)        330222\n",
       "Distance to Primary School (km)     330222\n",
       "Distance to Supermarket (km)        330222\n",
       "Distance to GP (km)                 330222\n",
       "Homelessness Rate                   330222\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing data identification\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421ae024-29bb-431c-9f37-89a0d90261e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3763863, 27)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #3763863 rows and 22 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3310fa3-2a35-4fef-a4c1-1a65fe586d60",
   "metadata": {},
   "source": [
    "Columns that are fully observed are- **Month, Location, crime type, force**. \n",
    "\n",
    "Data that needs mean imputing- **decile and rank data**.\n",
    "\n",
    "**Crime ID** needs randomised ID data to be the datasets primary key.\n",
    "\n",
    "**'Last outcome'** data needs nulls replaced with **'undefined outcome'** \n",
    "\n",
    "Nulls I will consider dropping- **LSOA code**, because this acts as a geographic anchor needed for mean imputation, so removing null LSOA can help achieve mean imputation. Common threshold for deleting missing data is < 5%, and LSOA are 0.86% null out of the entire dataset. \n",
    "\n",
    "**Original dataset** already saved in csv within the folder, following best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dae6ac7-5182-4f2f-b8fd-03ffb592ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['LSOA code'].notna()]\n",
    "#overwriting and dropping LSOA missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994c8ce6-c283-4bb1-9c84-ffb8d8570628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LSOA code'].isna().sum() #confirming no n/a left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee623402-7407-4082-b52b-e3dec7e551a2",
   "metadata": {},
   "source": [
    "### **Mean imputation/ filling in missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35b6191-a01f-4d7e-ab54-8b171379ad1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrime ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Apply row-wise and overwrite missing Crime IDs\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrime ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_crime_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1079\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1076\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1249\u001b[0m, in \u001b[0;36mFrameColumnApply.series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mseries_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[Series, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m-> 1249\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[0;32m   1250\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:862\u001b[0m, in \u001b[0;36mFrameApply.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:12664\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12590\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12593\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12594\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12662\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:1735\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m   1734\u001b[0m     rl \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mmgr_locs\n\u001b[1;32m-> 1735\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1736\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1737\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:2253\u001b[0m, in \u001b[0;36mEABackedBlock.get_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2251\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;66;03m# TODO(EA2D): reshape not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m-> 2253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#there are alot of missing crime ID's which are important for looking at the frequency of crime per areas\n",
    "#so we're going to generate unique ID's for nulls in the crime ID column \n",
    "import uuid\n",
    "\n",
    "# Function to generate a UUID if Crime ID is missing\n",
    "def generate_crime_id(row):\n",
    "    if pd.isna(row['Crime ID']):\n",
    "        return str(uuid.uuid4())\n",
    "    else:\n",
    "        return row['Crime ID']\n",
    "\n",
    "# Apply row-wise and overwrite missing Crime IDs\n",
    "df['Crime ID'] = df.apply(generate_crime_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca33428-43e0-4d53-b155-0e42c32f4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #making sure crime ID has as many unique ID's as the amount of rows within our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be015b3-07ae-409f-af0d-25d109b948fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validating that each crime ID is unique\n",
    "df['Crime ID'].nunique() #should have 3731377"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6017ad6-eb6e-4fc9-9ef3-0e9997c26138",
   "metadata": {},
   "source": [
    "This suggests there are duplicates which could skew our crime frequency analysis, we need each row to be unique to avoid grouping and count every single occurrence of crime, to accurately measure crime frequency. I will now run further sanity checks on if there are duplicates and where they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922fe80-4b39-46a6-a750-5a9eb9af19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crime ID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249c5b8-5bf3-441b-99ea-4553940f81e8",
   "metadata": {},
   "source": [
    "I have 38495 duplicates in my crime ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412b06c-9cd0-4c58-820e-200989c9fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Crime ID'].duplicated()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342747c-3005-4d3e-95e2-671fb6ad8202",
   "metadata": {},
   "source": [
    "This is an error wihtin the original data, as you can see, duplicates can't simply be dropped but need reassigning as each row is unique yet ID's are reused. Sometimes police forces bundle minor or nearby incidents under the same ID for reporting but can misrepresent crime frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b9e22-96b7-4139-af0b-612e560b92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() #counting entire row duplicates wihtin entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f121c-60b4-4350-8cc1-7fdabf80e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates() #removing entire row duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbea0f-c1ba-405e-8191-d038ac52297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crime ID'].duplicated().sum() #this has slightly reduced the amount of duplicates in crime ID but further unique identification is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2b890-ed4e-4e02-b057-644d33844746",
   "metadata": {},
   "source": [
    "Now I will create a new column which every row has a unique identifier, in place of the crime ID column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff95fe3-cec5-41b8-8e5a-a73d0e9234b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crime unique ID'] = [str(uuid.uuid4()) for _ in range(len(df))] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de8237-c61d-4fe4-ae55-ce7040831067",
   "metadata": {},
   "source": [
    "We must address the **last outcome** column. I will simply assign a new term 'unidentified outcome' in place of the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c847d6c-fe3b-460c-97cb-3641f31fc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last outcome category'] = df['Last outcome category'].fillna('Unidentified outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65baff2-0b52-438e-aa12-79e86a7048e2",
   "metadata": {},
   "source": [
    "Now I will impute every missing decile/ rank data point with their respective means from their LSOA code groups, I used LSOA code to impute means as that's what the datasets were joined together by. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ef555-84d9-418b-85ac-b29ec231c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute = [\n",
    "    'Income Deprivation Decile', 'Employment Deprivation Decile', 'Education Deprivation Decile',\n",
    "    'Housing Barrier Decile', 'Environment Deprivation Decile',\n",
    "    'Income Deprivation Rank', 'Employment Deprivation Rank', 'Education Deprivation Rank',\n",
    "    'Housing Barrier Rank', 'Environment Deprivation Rank', 'Crime Deprivation Rank', 'Crime Deprivation Decile'\n",
    "]\n",
    "\n",
    "for col in columns_to_impute:\n",
    "    df[col] = df.groupby('LSOA code')[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07814fb-8587-4653-ad26-eeec9b8f2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_to_impute].isnull().sum() #mean imputation did not work. This signals an issue with data incompleteness --> not enough data to compute mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaca2ca-27f7-4938-ad68-94b389e3c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_impute:\n",
    "    missing_lsoas = df[df[col].isna()]['LSOA code'].nunique()\n",
    "    print(f\"{col}: {missing_lsoas} LSOA codes have all missing values\")\n",
    "#this output will show us the data completeness regarding LSOA's and their respective ranks/ deciles.\n",
    "#most likely the diagnostic to why the mean imputaion is not working as intended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a4cc2-cd06-4c50-8633-5d7425cb3ad6",
   "metadata": {},
   "source": [
    "This highlights the severity of data incompleteness. Many LSOA code groups have no data at all to impute the mean. The original dataset lacked information on many LSOA's. What I will proceed to do instead is use broader groupby's such as force to re-conduct my mean imputation. Though this poses a threat to the granularity of our data, it is better than no data at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d324166-1ed1-4fc0-8e98-fe23b7e11988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values first by Force group mean\n",
    "for col in ['Income Deprivation Decile', 'Employment Deprivation Decile', 'Education Deprivation Decile', 'Housing Barrier Decile', 'Environment Deprivation Decile',\n",
    "            'Income Deprivation Rank', 'Employment Deprivation Rank', 'Education Deprivation Rank', 'Housing Barrier Rank', 'Environment Deprivation Rank',\n",
    "            'Distance to Post Office (km)', 'Distance to Primary School (km)',\n",
    "            'Distance to Supermarket (km)', 'Distance to GP (km)', 'Homelessness Rate', 'Crime Deprivation Rank', 'Crime Deprivation Decile']:\n",
    "\n",
    "    # Fallback: Fill remaining missing values using Force-level mean\n",
    "    df[col] = df.groupby('Force')[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4d53d-449b-430e-ab2e-44a9be8fccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5748c-dc3d-43da-8136-e4db71ed1c24",
   "metadata": {},
   "source": [
    "This improved mean imputation significantly, the remaining missing value columns will be dropped as they have significant data incompleteness and won't be useful for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447950ac-e34f-4872-9b80-80db2f126b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_final = [\n",
    "    'LSOA name_x', 'LSOA name_y',\n",
    "    'Income Deprivation Rank', 'Employment Deprivation Rank', 'Education Deprivation Rank',\n",
    "    'Housing Barrier Rank', 'Environment Deprivation Rank'\n",
    "]\n",
    "df.drop(columns=columns_to_drop_final, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea53bcd-7f51-40a4-b013-b9dc5c24a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea68e5b-0fd9-4425-8a92-4f396b32eea1",
   "metadata": {},
   "source": [
    "Data is fully complete, now we can move onto feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732a4ba-7dbf-4017-b3dc-cb05b7823672",
   "metadata": {},
   "source": [
    "### **Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda55109-993b-4652-850b-7e2cc1a50c0b",
   "metadata": {},
   "source": [
    "Here I am creating a variable that represents the access to integral services like schools, supermarkets, GP's etc. called **service access**, and make real estate decisions based on 'service desserts' and their relation to crime. I want to standardise the index/ decile data, as lower values represent more deprivation/ worser outcomes which can be misleading and hinders interpretability. Lastly, I want to make a monthly time lagged crime_count variable, time lagged variables are pivotal for machine learning models to analyse incremental temporal changes in crime, and can also be used to predict future increase/decreases in crime level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf8158-be02-4e3f-97f0-3319d0d7d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service_access'] = df[\n",
    "    ['Distance to Post Office (km)', 'Distance to Primary School (km)', \n",
    "     'Distance to Supermarket (km)', 'Distance to GP (km)']\n",
    "].mean(axis=1)\n",
    "\n",
    "#created my service access variable by averaging distance columns to services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f602c-eb57-438d-a467-c96875b33c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crime_count'] = df['LSOA code'].map(df['LSOA code'].value_counts())\n",
    "#this counts the number of crimes in an LSOA area, since every row is a unique crime, it essentially counts the number of recorded crimes in each area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed344ec-e3dc-464f-a339-6c3fa3d5f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating my time lagged variable-- to predict increases in crime frequency using ML time series models\n",
    "df.sort_values(by=['Force', 'Month'], inplace=True)\n",
    "# sorting data by date and force, necessary for machine learning time series models \n",
    "\n",
    "df['lagged_crime_count'] = df.groupby('Force')['crime_count'].shift(1)\n",
    "# lagging crime count, this creates a variable where every row represents data from a month prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f88ac4-5561-4871-a2e6-b108012006cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating crime group column to do categorical analysis on in EDA. Creating broader groups. \n",
    "def map_crime_type(x):\n",
    "    if x in ['Violence and sexual offences', 'Robbery', 'Possession of weapons']:\n",
    "        return 'Violent'\n",
    "    elif x in ['Burglary', 'Vehicle crime', 'Other theft', 'Shoplifting', 'Theft from the person']:\n",
    "        return 'Property'\n",
    "    elif x in ['Anti-social behaviour', 'Public order']:\n",
    "        return 'Anti-social'\n",
    "    elif x == 'Drugs':\n",
    "        return 'Drugs'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['crime_category'] = df['Crime type'].apply(map_crime_type) #using apply method to apply custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe076930-2966-4241-8658-ad76ff610af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing index/decile data to make it more readable (higher values indicate worse outcome)\n",
    "# Reverse RANKS\n",
    "df['Crime Deprivation Rank'] = (df['Crime Deprivation Rank'].max() + 1) - df['Crime Deprivation Rank']\n",
    "\n",
    "# Reverse DECILES\n",
    "df['Income Deprivation Decile'] = 11 - df['Income Deprivation Decile']\n",
    "df['Employment Deprivation Decile'] = 11 - df['Employment Deprivation Decile']\n",
    "df['Education Deprivation Decile'] = 11 - df['Education Deprivation Decile']\n",
    "df['Crime Deprivation Decile'] = 11 - df['Crime Deprivation Decile']\n",
    "df['Environment Deprivation Decile'] = 11 - df['Environment Deprivation Decile']\n",
    "df['Housing Barrier Decile'] = 11 - df['Housing Barrier Decile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f636b3e-996e-4249-8162-6dd95305f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_data.csv\", index=False)\n",
    "#saving final cleaned dataset to the directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
